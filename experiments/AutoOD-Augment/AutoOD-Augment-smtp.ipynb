{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import logging\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "def run_lof(X, y, k=60):\n",
    "    clf = LocalOutlierFactor(n_neighbors=k)\n",
    "    clf.fit(X)\n",
    "    lof_scores = -clf.negative_outlier_factor_\n",
    "    return lof_scores\n",
    "\n",
    "def get_predictions(scores, num_outliers = 400, method_name = 'LOF'):\n",
    "    threshold = np.sort(scores)[::-1][num_outliers]\n",
    "    # threshold, max_f1 = get_best_f1_score(y, lof_scores)\n",
    "    predictions = np.array(scores > threshold)\n",
    "    predictions = np.array([int(i) for i in predictions])\n",
    "#     print('F1 for {} : {}'.format(method_name, metrics.f1_score(y, predictions)))\n",
    "    return predictions, scores, metrics.f1_score(y, predictions)\n",
    "\n",
    "def get_precision_recall(scores, num_outliers = 400, method_name = 'LOF'):\n",
    "    threshold = np.sort(scores)[::-1][num_outliers]\n",
    "    # threshold, max_f1 = get_best_f1_score(y, lof_scores)\n",
    "    predictions = np.array(scores > threshold)\n",
    "    predictions = np.array([int(i) for i in predictions])\n",
    "#     print('F1 for {} : {}'.format(method_name, metrics.f1_score(y, predictions)))\n",
    "    return predictions, scores, metrics.f1_score(y, predictions), metrics.precision_score(y, predictions), metrics.recall_score(y, predictions)\n",
    "\n",
    "def get_best_F1(scores):\n",
    "    best_f1 = 0\n",
    "    for i in range(np.shape(scores)[0]):\n",
    "        threshold = np.sort(scores)[::-1][i]\n",
    "        predictions = np.array(scores > threshold)\n",
    "        predictions = np.array([int(i) for i in predictions])\n",
    "        cur_f1 = metrics.f1_score(y, predictions)\n",
    "        best_f1 = max(cur_f1, best_f1)\n",
    "    return best_f1\n",
    "\n",
    "def run_knn(X, y, k=60):\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(X)\n",
    "    knn_dists = neigh.kneighbors(X)[0][:,-1]\n",
    "    return knn_dists\n",
    "\n",
    "def run_isolation_forest(X, y, max_features = 1.0):\n",
    "    # training the model\n",
    "    clf = IsolationForest(random_state=42,max_features=max_features)\n",
    "    clf.fit(X)\n",
    "    # predictions\n",
    "    sklearn_score_anomalies = clf.decision_function(X)\n",
    "    if_scores = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
    "    return if_scores\n",
    "\n",
    "def mahalanobis(x):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(x)\n",
    "    cov = np.cov(x.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    results = []\n",
    "    x_minus_mu = np.array(x_minus_mu)\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        cur_data = x_minus_mu[i,:]\n",
    "        results.append(np.dot(np.dot(x_minus_mu[i,:], inv_covmat), x_minus_mu[i,:].T))\n",
    "    return np.array(results)\n",
    "#     left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "#     mahal = np.dot(left_term, x_minus_mu.T)\n",
    "#     print(mahal.diagonal())\n",
    "#     return mahal.diagonal()\n",
    "\n",
    "def run_mahalanobis(X, y):\n",
    "    # training the model\n",
    "    dist = mahalanobis(x=X)\n",
    "    return dist\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data, meta = arff.loadarff(f)\n",
    "    data = pd.DataFrame(data)\n",
    "    X = data.drop(columns=['id', 'outlier'])\n",
    "    # Map dataframe to encode values and put values into a numpy array\n",
    "    y = data[\"outlier\"].map(lambda x: 1 if x == b'yes' else 0).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load smtp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95156\n",
      "30.0\n",
      "0.0003152717642607928\n"
     ]
    }
   ],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('smtp.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "print(len(y))\n",
    "print(np.sum(y))\n",
    "\n",
    "lof_krange = list(range(10,110,10)) * 6\n",
    "knn_krange = list(range(10,110,10)) * 6\n",
    "if_range = [0.5, 0.6, 0.7, 0.8, 0.9] * 6\n",
    "# mahalanobis_N_range=[20, 40, 60, 80, 100, 120]\n",
    "mahalanobis_N_range=[30, 60, 90, 120, 150, 180]\n",
    "# mahalanobis_N_range = [30, 40, 50, 60, 70,80]\n",
    "# mahalanobis_N_range = [200, 400, 600, 800, 1000, 1200]\n",
    "if_N_range = np.sort(mahalanobis_N_range * 5)\n",
    "N_range = np.sort(mahalanobis_N_range *10)\n",
    "print(np.sum(y)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.6\n",
      "0.8\n",
      "0.9\n",
      "0.7\n",
      "Average F1s = 0.0, Average Precision = 0.0, Average recall = 0.0\n",
      "Max F1s = 0.0, Precision at best F1 = 0, recall at best F1 = 0\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "temp_if_results = dict()\n",
    "unique_if_features = list(set(if_range)) \n",
    "best_f1 = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "for k in unique_if_features:\n",
    "    print(k)\n",
    "    if_scores = run_isolation_forest(X, y, max_features=k)\n",
    "    temp_if_results[k] = if_scores\n",
    "for i in range(len(if_range)):\n",
    "    if_predictions, if_scores,f1, precision, recall = get_precision_recall(temp_if_results[if_range[i]], num_outliers=if_N_range[i], method_name='IF')\n",
    "    f1s.append(f1)\n",
    "    if f1>best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "print(f\"Average F1s = {sum(f1s)/len(f1s)}, Average Precision = {sum(precisions)/len(precisions)}, Average recall = {sum(recalls)/len(recalls)}\")\n",
    "print(f\"Max F1s = {max(f1s)}, Precision at best F1 = {best_precision}, recall at best F1 = {best_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best Unsupervised Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1a80cd998c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtemp_lof_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlof_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlof_krange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mlof_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlof_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_precision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_lof_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlof_krange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outliers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlof_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlof_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5f8aba8fdaa0>\u001b[0m in \u001b[0;36mget_precision_recall\u001b[0;34m(scores, num_outliers, method_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     print('F1 for {} : {}'.format(method_name, metrics.f1_score(y, predictions)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_F1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1462\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                          str(average_options))\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "all_scores = []\n",
    "f1s = []\n",
    "\n",
    "method_to_bestf1 = {}\n",
    "best_f1 = 0\n",
    "best_precision=0\n",
    "best_recall=0\n",
    "\n",
    "temp_lof_results = dict()\n",
    "unique_lof_ks = list(set(lof_krange)) \n",
    "\n",
    "best_lof_f1 = 0\n",
    "best_lof_precision = 0\n",
    "best_lof_recall = 0\n",
    "for k in unique_lof_ks:\n",
    "#     print(k)\n",
    "    lof_scores = run_lof(X, y, k=k)\n",
    "    temp_lof_results[k] = lof_scores\n",
    "for i in range(len(lof_krange)):\n",
    "    lof_predictions, lof_scores, f1, precision,recall = get_precision_recall(temp_lof_results[lof_krange[i]], num_outliers=N_range[i], method_name='LOF')\n",
    "    all_results.append(lof_predictions)\n",
    "    all_scores.append(lof_scores)\n",
    "    f1s.append(f1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "\n",
    "best_lof_f1 = 0\n",
    "for i in np.sort(unique_lof_ks):\n",
    "    temp_f1 = max(np.array(f1s[0:60])[np.where(np.array(lof_krange) == i)[0]])\n",
    "    best_lof_f1 = max(best_lof_f1, temp_f1)\n",
    "\n",
    "method_to_bestf1[\"LOF\"] = best_lof_f1\n",
    "\n",
    "temp_knn_results = dict()\n",
    "unique_knn_ks = list(set(knn_krange)) \n",
    "for k in unique_knn_ks:\n",
    "    knn_scores = run_knn(X, y, k=k)\n",
    "    temp_knn_results[k] = knn_scores\n",
    "for i in range(len(knn_krange)):\n",
    "    knn_predictions, knn_scores,f1,precision,recall = get_precision_recall(temp_knn_results[knn_krange[i]], num_outliers=N_range[i], method_name='KNN')\n",
    "    all_results.append(knn_predictions)\n",
    "    all_scores.append(knn_scores)\n",
    "    f1s.append(f1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "best_knn_f1 = 0\n",
    "for i in np.sort(unique_knn_ks):\n",
    "    temp_f1 = max(np.array(f1s[60:120])[np.where(np.array(knn_krange) == i)[0]])\n",
    "    best_knn_f1 = max(best_knn_f1, temp_f1)\n",
    "method_to_bestf1[\"KNN\"] = best_knn_f1\n",
    "\n",
    "temp_if_results = dict()\n",
    "unique_if_features = list(set(if_range)) \n",
    "for k in unique_if_features:\n",
    "    if_scores = run_isolation_forest(X, y, max_features=k)\n",
    "    temp_if_results[k] = if_scores\n",
    "for i in range(len(if_range)):\n",
    "    if_predictions, if_scores,f1,precision,recall = get_precision_recall(temp_if_results[if_range[i]], num_outliers=if_N_range[i], method_name='IF')\n",
    "    all_results.append(if_predictions)\n",
    "    all_scores.append(if_scores)\n",
    "    f1s.append(f1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "best_if_f1 = 0\n",
    "for i in np.sort(unique_if_features):\n",
    "    temp_f1 = max(np.array(f1s[120:150])[np.where(np.array(if_range) == i)[0]])\n",
    "    best_if_f1 = max(best_if_f1, temp_f1)\n",
    "method_to_bestf1[\"IF\"] = best_if_f1\n",
    "   \n",
    "mahalanobis_scores = run_mahalanobis(X, y)\n",
    "best_mahala_f1 = 0\n",
    "for i in range(len(mahalanobis_N_range)):\n",
    "    mahalanobis_predictions,mahalanobis_scores,f1,precision,recall = get_precision_recall(mahalanobis_scores, num_outliers=mahalanobis_N_range[i], method_name='mahala')\n",
    "    all_results.append(mahalanobis_predictions)\n",
    "    all_scores.append(mahalanobis_scores)\n",
    "    best_mahala_f1 = max(best_mahala_f1, f1)\n",
    "    f1s.append(f1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "method_to_bestf1[\"Mahala\"] = best_mahala_f1\n",
    "best_method = \"\"\n",
    "best_f1 =0\n",
    "for method, f1 in method_to_bestf1.items():\n",
    "    if f1 > best_f1:\n",
    "        best_method = method\n",
    "        best_f1 = f1\n",
    "\n",
    "print(f\"Best Method = {best_method}, Best F1 = {best_f1}\")\n",
    "L = np.stack(all_results).T\n",
    "scores = np.stack(all_scores).T\n",
    "print(f\"Best F1 = {best_f1}, best_precision = {best_precision}, best_recall={best_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOF': 0.6, 'KNN': 0.6666666666666666, 'IF': 0, 'Mahala': 0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_to_bestf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95156, 156)\n",
      "(95156, 156)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(L))\n",
    "print(np.shape(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 for MV: 0.4074074074074074\n"
     ]
    }
   ],
   "source": [
    "mid = np.shape(L)[1]/2\n",
    "predictions = np.full((len(y)), 0)\n",
    "predictions[np.sum(L, axis = 1) > mid] = 1\n",
    "print('F1 for MV:', metrics.f1_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_prev = L\n",
    "scores_prev = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = L_prev\n",
    "scores = scores_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95156, 156)\n"
     ]
    }
   ],
   "source": [
    "# print(max(f1s)) \n",
    "print(np.shape(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result_list = []\n",
    "classifier_result_list = []\n",
    "prediction_list = []\n",
    "cur_f1_scores = []\n",
    "prediction_high_conf_outliers = np.array([])\n",
    "prediction_high_conf_inliers = np.array([])\n",
    "prediction_classifier_disagree = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_range = np.array([[0, 60], [60, 120],[120,150],[150,156]])\n",
    "coef_index_range = np.array([[0, 10], [10, 20],[20,25],[25,26]])\n",
    "coef_remain_index = range(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 120, 121, 122, 123, 124, 150]\n",
      "(95156, 26)\n"
     ]
    }
   ],
   "source": [
    "scores_for_training_indexes = []\n",
    "for i in range(len(index_range)):\n",
    "    start=index_range[i][0]\n",
    "    temp_range = coef_index_range[i][1]-coef_index_range[i][0]\n",
    "    scores_for_training_indexes  = scores_for_training_indexes + list(range(start, start+temp_range))\n",
    "print(scores_for_training_indexes) \n",
    "scores_for_training = scores[:, np.array(scores_for_training_indexes)]\n",
    "print(np.shape(scores_for_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative train LR and classifier(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "Iteration = 0, L shape = (95156, 156)\n",
      "All agree, Number of outliers = 0\n",
      "All agree, Number of inliers = 94182\n",
      "num of inliers = 94182\n",
      "num of outliers = 0\n",
      "num of outliers = 37\n",
      "Training data shape:  (94219, 26)\n",
      "Training data F-1 0.5970149253731343\n",
      "F-1 score from LR: 0.20512820512820512\n",
      "(94219, 3)\n",
      "(94219,)\n",
      "F-1 score from SVM: 0.4545454545454545\n",
      "length of prediction_high_conf_outliers: 36\n",
      "length of prediction high conf inliers:  94481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 1  3  4  7  8 12 13 14 15 25]\n",
      "[[ 0  5]\n",
      " [ 5  9]\n",
      " [ 9  9]\n",
      " [ 9 10]]\n",
      "[[ 0 30]\n",
      " [30 54]\n",
      " [54 54]\n",
      " [54 60]]\n",
      "##################################################################\n",
      "Iteration = 1, L shape = (95156, 60)\n",
      "All agree, Number of outliers = 6\n",
      "All agree, Number of inliers = 94527\n",
      "num of inliers = 94144\n",
      "num of outliers = 36\n",
      "num of outliers = 36\n",
      "Training data shape:  (94180, 10)\n",
      "Training data F-1 0.606060606060606\n",
      "F-1 score from LR: 0.18604651162790697\n",
      "(94180, 3)\n",
      "(94180,)\n",
      "F-1 score from SVM: 0.4444444444444444\n",
      "length of prediction_high_conf_outliers: 34\n",
      "length of prediction high conf inliers:  94733\n",
      "0.026408743040499255\n",
      "[ 7  8 12 13 14 15 25]\n",
      "[[0 2]\n",
      " [2 6]\n",
      " [6 6]\n",
      " [6 7]]\n",
      "[[ 0 12]\n",
      " [12 36]\n",
      " [36 36]\n",
      " [36 42]]\n",
      "##################################################################\n",
      "Iteration = 2, L shape = (95156, 42)\n",
      "All agree, Number of outliers = 6\n",
      "All agree, Number of inliers = 94666\n",
      "num of inliers = 94519\n",
      "num of outliers = 34\n",
      "num of outliers = 34\n",
      "Training data shape:  (94553, 7)\n",
      "Training data F-1 0.625\n",
      "F-1 score from LR: 0.18691588785046725\n",
      "(94553, 3)\n",
      "(94553,)\n",
      "F-1 score from SVM: 0.5405405405405405\n",
      "length of prediction_high_conf_outliers: 33\n",
      "length of prediction high conf inliers:  94833\n",
      "0.07730575317829153\n",
      "[ 7  8 12 13 14 15]\n",
      "[[0 2]\n",
      " [2 6]\n",
      " [6 6]\n",
      " [6 6]]\n",
      "[[ 0 12]\n",
      " [12 36]\n",
      " [36 36]\n",
      " [36 36]]\n",
      "##################################################################\n",
      "Iteration = 3, L shape = (95156, 36)\n",
      "All agree, Number of outliers = 15\n",
      "All agree, Number of inliers = 94838\n",
      "num of inliers = 94742\n",
      "num of outliers = 33\n",
      "num of outliers = 33\n",
      "Training data shape:  (94775, 6)\n",
      "Training data F-1 0.6349206349206349\n",
      "F-1 score from LR: 0.2150537634408602\n",
      "(94775, 3)\n",
      "(94775,)\n",
      "F-1 score from SVM: 0.5797101449275363\n",
      "length of prediction_high_conf_outliers: 32\n",
      "length of prediction high conf inliers:  94890\n",
      "0.11059218410167491\n",
      "[ 8 12 13 14 15]\n",
      "[[0 1]\n",
      " [1 5]\n",
      " [5 5]\n",
      " [5 5]]\n",
      "[[ 0  6]\n",
      " [ 6 30]\n",
      " [30 30]\n",
      " [30 30]]\n",
      "##################################################################\n",
      "Iteration = 4, L shape = (95156, 30)\n",
      "All agree, Number of outliers = 24\n",
      "All agree, Number of inliers = 94852\n",
      "num of inliers = 94791\n",
      "num of outliers = 32\n",
      "num of outliers = 32\n",
      "Training data shape:  (94823, 5)\n",
      "Training data F-1 0.6451612903225806\n",
      "F-1 score from LR: 0.2285714285714286\n",
      "(94823, 3)\n",
      "(94823,)\n",
      "F-1 score from SVM: 0.6349206349206349\n",
      "length of prediction_high_conf_outliers: 31\n",
      "length of prediction high conf inliers:  94914\n",
      "0.12535031642918737\n",
      "[ 8 12 13 14]\n",
      "[[0 1]\n",
      " [1 4]\n",
      " [4 4]\n",
      " [4 4]]\n",
      "[[ 0  6]\n",
      " [ 6 24]\n",
      " [24 24]\n",
      " [24 24]]\n",
      "##################################################################\n",
      "Iteration = 5, L shape = (95156, 24)\n",
      "All agree, Number of outliers = 24\n",
      "All agree, Number of inliers = 94861\n",
      "num of inliers = 94822\n",
      "num of outliers = 31\n",
      "num of outliers = 31\n",
      "Training data shape:  (94853, 4)\n",
      "Training data F-1 0.6557377049180327\n",
      "F-1 score from LR: 0.24390243902439024\n",
      "(94853, 3)\n",
      "(94853,)\n",
      "F-1 score from SVM: 0.6557377049180327\n",
      "length of prediction_high_conf_outliers: 29\n",
      "length of prediction high conf inliers:  94932\n",
      "0.09625657021163318\n",
      "[12 13 14]\n",
      "[[0 0]\n",
      " [0 3]\n",
      " [3 3]\n",
      " [3 3]]\n",
      "[[ 0  0]\n",
      " [ 0 18]\n",
      " [18 18]\n",
      " [18 18]]\n",
      "##################################################################\n",
      "Iteration = 6, L shape = (95156, 18)\n",
      "All agree, Number of outliers = 29\n",
      "All agree, Number of inliers = 94963\n",
      "num of inliers = 94920\n",
      "num of outliers = 30\n",
      "num of outliers = 29\n",
      "Training data shape:  (94949, 3)\n",
      "Training data F-1 0.6779661016949153\n",
      "F-1 score from LR: 0.29411764705882354\n",
      "(94949, 3)\n",
      "(94949,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 27\n",
      "length of prediction high conf inliers:  94964\n",
      "0.069464229918041\n",
      "[12 13]\n",
      "[[0 0]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [2 2]]\n",
      "[[ 0  0]\n",
      " [ 0 12]\n",
      " [12 12]\n",
      " [12 12]]\n",
      "##################################################################\n",
      "Iteration = 7, L shape = (95156, 12)\n",
      "All agree, Number of outliers = 29\n",
      "All agree, Number of inliers = 94972\n",
      "num of inliers = 94942\n",
      "num of outliers = 29\n",
      "num of outliers = 28\n",
      "Training data shape:  (94970, 2)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.6349206349206349\n",
      "(94970, 3)\n",
      "(94970,)\n",
      "F-1 score from SVM: 0.7017543859649122\n",
      "length of prediction_high_conf_outliers: 27\n",
      "length of prediction high conf inliers:  95046\n",
      "0.10180149806380463\n",
      "[13]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [0 6]\n",
      " [6 6]\n",
      " [6 6]]\n",
      "##################################################################\n",
      "Iteration = 8, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94979\n",
      "num of inliers = 94979\n",
      "num of outliers = 30\n",
      "num of outliers = 28\n",
      "Training data shape:  (95007, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.3883495145631068\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95032\n",
      "##################################################################\n",
      "Iteration = 9, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94979\n",
      "num of inliers = 94979\n",
      "num of outliers = 30\n",
      "num of outliers = 28\n",
      "Training data shape:  (95007, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.3883495145631068\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95032\n",
      "##################################################################\n",
      "Iteration = 10, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94979\n",
      "num of inliers = 94979\n",
      "num of outliers = 30\n",
      "num of outliers = 28\n",
      "Training data shape:  (95007, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.3883495145631068\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95032\n",
      "##################################################################\n",
      "Iteration = 11, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94979\n",
      "num of inliers = 94979\n",
      "num of outliers = 30\n",
      "num of outliers = 28\n",
      "Training data shape:  (95007, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.3883495145631068\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95032\n",
      "##################################################################\n",
      "Iteration = 12, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94979\n",
      "num of inliers = 94979\n",
      "num of outliers = 30\n",
      "num of outliers = 28\n",
      "Training data shape:  (95007, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "F-1 score from LR: 0.3883495145631068\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95032\n"
     ]
    }
   ],
   "source": [
    "# stable version\n",
    "high_confidence_threshold = 0.99\n",
    "low_confidence_threshold = 0.001\n",
    "max_iter = 500\n",
    "remain_params_tracking = np.array(range(0,np.max(coef_index_range)))\n",
    "training_data_F1 = []\n",
    "two_prediction_corr = []\n",
    "\n",
    "min_max_diff = []\n",
    "N_size = 6\n",
    "\n",
    "last_training_data_indexes = []\n",
    "counter = 0\n",
    "\n",
    "for i_range in range(0, 50):\n",
    "    print(\"##################################################################\")\n",
    "    print('Iteration = {}, L shape = {}'.format(i_range, np.shape(L)))\n",
    "    num_methods = np.shape(L)[1]\n",
    "\n",
    "    agree_outlier_indexes = np.sum(L,axis=1)==np.shape(L)[1]\n",
    "    print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "    agree_inlier_indexes = np.sum(L,axis=1)==0\n",
    "    print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "    disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "\n",
    "    all_inlier_indexes = np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    if len(prediction_high_conf_inliers) > 0:\n",
    "        all_inlier_indexes = np.intersect1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "    print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "\n",
    "    all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    all_inlier_indexes = np.setdiff1d(all_inlier_indexes, prediction_classifier_disagree)\n",
    "    \n",
    "    self_agree_index_list = []\n",
    "    if((len(all_outlier_indexes) == 0) or (len(all_inlier_indexes)/ len(all_outlier_indexes) > 1000)):\n",
    "        for i in range(0, len(index_range)):\n",
    "            if(index_range[i,1]-index_range[i,0] <= 6):\n",
    "                continue\n",
    "            temp_index = disagree_indexes[np.where(np.sum(L[disagree_indexes][:,index_range[i,0]: index_range[i,1]], axis = 1)==(index_range[i,1]-index_range[i,0]))[0]]\n",
    "            self_agree_index_list = np.union1d(self_agree_index_list, temp_index)\n",
    "        self_agree_index_list = [int(i) for i in self_agree_index_list]\n",
    "#     self_agree_index_list = np.random.RandomState(1).permutation(self_agree_index_list)[:500]\n",
    "    all_outlier_indexes = np.union1d(all_outlier_indexes, self_agree_index_list)\n",
    "    all_outlier_indexes = np.setdiff1d(all_outlier_indexes, prediction_classifier_disagree)\n",
    "    print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    data_indexes = np.concatenate((all_inlier_indexes, all_outlier_indexes), axis = 0)\n",
    "    data_indexes = np.array([int(i) for i in data_indexes])\n",
    "    labels = np.concatenate((np.zeros(len(all_inlier_indexes)), np.ones(len(all_outlier_indexes))), axis = 0)\n",
    "    transformer = RobustScaler().fit(scores_for_training)\n",
    "    scores_transformed = transformer.transform(scores_for_training)\n",
    "    training_data = scores_transformed[data_indexes]\n",
    "    print('Training data shape: ', np.shape(training_data))\n",
    "    training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "    print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "#     clf = SVC(gamma='auto', probability=True, random_state=0)\n",
    "#     clf.fit(training_data, labels)\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "    clf_predictions = clf.predict(scores_transformed)\n",
    "    clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "    print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > 0.5])))\n",
    "    \n",
    "    \n",
    "    transformer = RobustScaler().fit(X)\n",
    "    X_transformed = transformer.transform(X)\n",
    "    X_training_data = X_transformed[data_indexes]\n",
    "    print(np.shape(X_training_data))\n",
    "    print(np.shape(labels))\n",
    "\n",
    "    clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "    clf_X.fit(X_training_data, labels)\n",
    "    clf_predictions_X = clf_X.predict(X_transformed)\n",
    "    clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "    print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    \n",
    "    agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "    agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "        \n",
    "    prediction_result_list.append(clf_predict_proba)\n",
    "    classifier_result_list.append(clf_predict_proba_X)\n",
    "    \n",
    "    prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "    \n",
    "    prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "    print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "    prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "    print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "    \n",
    "    temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > 0.5])\n",
    "    temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "    prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "#     print('length of prediction-classifier disagree: {}'.format(len(prediction_classifier_disagree)))\n",
    "#     print('length of prediction-classifier disagree in training: {}'.format(len(np.where(temp_prediction[data_indexes] != temp_classifier[data_indexes])[0])))\n",
    "#     print(np.corrcoef(clf_predict_proba,clf_predict_proba_X))\n",
    "    two_prediction_corr.append(np.corrcoef(clf_predict_proba,clf_predict_proba_X)[0,1])\n",
    "\n",
    "    if np.max(coef_index_range) >= 2:\n",
    "        if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "            new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "            new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "            new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "            clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "            combined_coef = clf_prune_2.coef_[0]  \n",
    "        else:\n",
    "            print('Coef from normal training: ', clf.coef_[0])\n",
    "            combined_coef = clf.coef_[0]\n",
    "            print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "        if(np.max(coef_index_range) >= 2):\n",
    "            if(len(set(combined_coef)) > 1):\n",
    "                cur_clf_coef = combined_coef \n",
    "                cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "                print(cutoff)\n",
    "\n",
    "                remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "                remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "                print(remain_params_tracking)\n",
    "                remain_indexes_after_cond_expanded = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                    s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                    saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                    for j in range(N_size):\n",
    "                        remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "                new_coef_index_range_seq = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "                coef_index_range = []\n",
    "                index_range = []\n",
    "                cur_sum = 0\n",
    "                for i in range(0, len(new_coef_index_range_seq)):\n",
    "                    coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                    index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                    cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "                coef_index_range = np.array(coef_index_range)\n",
    "                index_range = np.array(index_range)\n",
    "                print(coef_index_range)\n",
    "                print(index_range)\n",
    "\n",
    "                L=L[:,remain_indexes_after_cond_expanded]\n",
    "                scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "    if((len(last_training_data_indexes) == len(data_indexes)) and \n",
    "       (sum(last_training_data_indexes == data_indexes) == len(data_indexes)) and \n",
    "       (np.max(coef_index_range) < 2)):\n",
    "        counter =  counter + 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if(counter > 3):\n",
    "        break\n",
    "    last_training_data_indexes = data_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "(95156, 20)\n",
      "Training data shape:  (95007, 20)\n",
      "Training data F-1 0.689655172413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score from LR: 0.6349206349206349\n",
      "(95007, 3)\n",
      "(95007,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95091\n",
      "F-1 score from both LR and SVM: 0.6349206349206349\n",
      "Coef from both LR and SVM:  [-1.61980314e-06  1.04050349e-02 -6.41639058e-02  3.04253531e-02\n",
      "  4.96045106e-02 -7.89880615e-02 -2.38194332e-02  4.04246032e-02\n",
      "  8.18732903e-02 -3.37277446e-02  1.09745082e-01  3.84137917e-02\n",
      " -6.82626956e-03 -2.50414029e-02 -3.02556043e-02 -2.77038501e-02\n",
      " -2.24811525e-02 -2.33700442e-02 -2.29412416e-02 -1.87839267e-02]\n",
      "0\n",
      "[ 1  3  4  7  8 10 11]\n",
      "[[0 5]\n",
      " [5 7]]\n",
      "[[ 0 30]\n",
      " [30 42]]\n"
     ]
    }
   ],
   "source": [
    "index_range = np.array([[0, 60], [60, 120]])\n",
    "coef_index_range = np.array([[0, 10], [10, 20]])\n",
    "coef_remain_index = range(120)\n",
    "\n",
    "scores_for_training_indexes = []\n",
    "for i in range(len(index_range)):\n",
    "    start=index_range[i][0]\n",
    "    temp_range = coef_index_range[i][1]-coef_index_range[i][0]\n",
    "    scores_for_training_indexes  = scores_for_training_indexes + list(range(start, start+temp_range))\n",
    "print(scores_for_training_indexes) \n",
    "scores_for_training = scores[:, np.array(scores_for_training_indexes)]\n",
    "print(np.shape(scores_for_training))\n",
    "\n",
    "transformer = RobustScaler().fit(scores_for_training)\n",
    "scores_transformed = transformer.transform(scores_for_training)\n",
    "training_data = scores_transformed[data_indexes]\n",
    "print('Training data shape: ', np.shape(training_data))\n",
    "training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "clf_predictions = clf.predict(scores_transformed)\n",
    "clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > 0.5])))\n",
    "\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_transformed = transformer.transform(X)\n",
    "X_training_data = X_transformed[data_indexes]\n",
    "print(np.shape(X_training_data))\n",
    "print(np.shape(labels))\n",
    "\n",
    "clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "clf_X.fit(X_training_data, labels)\n",
    "clf_predictions_X = clf_X.predict(X_transformed)\n",
    "clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "cur_f1_scores.append(metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "\n",
    "agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "\n",
    "prediction_result_list.append(clf_predict_proba)\n",
    "classifier_result_list.append(clf_predict_proba_X)\n",
    "\n",
    "prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "\n",
    "prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                               np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                               np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "\n",
    "temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > 0.5])\n",
    "temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "\n",
    "L = L_prev\n",
    "remain_params_tracking = np.array(range(0,np.max(coef_index_range)))\n",
    "\n",
    "if np.max(coef_index_range) >= 2:\n",
    "    if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "        new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "        new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "        new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "        clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "        print(\"F-1 score from both LR and SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_prune_2.predict_proba(scores_transformed)[:,1] > 0.5])))\n",
    "        print('Coef from both LR and SVM: ', clf_prune_2.coef_[0])\n",
    "        combined_coef = clf_prune_2.coef_[0]  \n",
    "    else:\n",
    "        print('Coef from normal training: ', clf.coef_[0])\n",
    "        combined_coef = clf.coef_[0]\n",
    "        print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "    if(np.max(coef_index_range) > 2 or \n",
    "       ((np.max(combined_coef)/np.min(combined_coef) >= 1.1) and np.max(coef_index_range) >= 2)):\n",
    "        if(len(set(combined_coef)) > 1):\n",
    "            cur_clf_coef = combined_coef \n",
    "            cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "            print(cutoff)\n",
    "\n",
    "            remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "            remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "            print(remain_params_tracking)\n",
    "            remain_indexes_after_cond_expanded = []\n",
    "            for i in range(0, len(coef_index_range)): #\n",
    "                s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                for j in range(N_size):\n",
    "                    remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "            new_coef_index_range_seq = []\n",
    "            for i in range(0, len(coef_index_range)): #\n",
    "                s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "            coef_index_range = []\n",
    "            index_range = []\n",
    "            cur_sum = 0\n",
    "            for i in range(0, len(new_coef_index_range_seq)):\n",
    "                coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "            coef_index_range = np.array(coef_index_range)\n",
    "            index_range = np.array(index_range)\n",
    "            print(coef_index_range)\n",
    "            print(index_range)\n",
    "\n",
    "            L=L[:,remain_indexes_after_cond_expanded]\n",
    "            scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################\n",
      "Iteration = 0, L shape = (95156, 42)\n",
      "All agree, Number of outliers = 6\n",
      "All agree, Number of inliers = 94692\n",
      "num of inliers = 94692\n",
      "num of outliers = 28\n",
      "num of outliers = 28\n",
      "Training data shape:  (94720, 7)\n",
      "Training data F-1 0.689655172413793\n",
      "(94720, 3)\n",
      "(94720,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95058\n",
      "F-1 score from both LR and SVM: 0.41666666666666663\n",
      "Coef from both LR and SVM:  [-0.00944481  0.00878645  0.03105893  0.040672    0.03143341  0.03365675\n",
      "  0.01982147]\n",
      "0.00614506146656546\n",
      "[ 3  4  7  8 10 11]\n",
      "[[0 4]\n",
      " [4 6]]\n",
      "[[ 0 24]\n",
      " [24 36]]\n",
      "##################################################################\n",
      "Iteration = 1, L shape = (95156, 36)\n",
      "All agree, Number of outliers = 6\n",
      "All agree, Number of inliers = 94773\n",
      "num of inliers = 94767\n",
      "num of outliers = 28\n",
      "num of outliers = 29\n",
      "Training data shape:  (94796, 6)\n",
      "Training data F-1 0.6779661016949153\n",
      "(94796, 3)\n",
      "(94796,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95050\n",
      "F-1 score from both LR and SVM: 0.425531914893617\n",
      "Coef from both LR and SVM:  [0.00164728 0.03165849 0.04098749 0.02663971 0.03967369 0.02213414]\n",
      "0.013929724083017148\n",
      "[ 4  7  8 10 11]\n",
      "[[0 3]\n",
      " [3 5]]\n",
      "[[ 0 18]\n",
      " [18 30]]\n",
      "##################################################################\n",
      "Iteration = 2, L shape = (95156, 30)\n",
      "All agree, Number of outliers = 11\n",
      "All agree, Number of inliers = 94788\n",
      "num of inliers = 94781\n",
      "num of outliers = 28\n",
      "num of outliers = 28\n",
      "Training data shape:  (94809, 5)\n",
      "Training data F-1 0.689655172413793\n",
      "(94809, 3)\n",
      "(94809,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95078\n",
      "F-1 score from both LR and SVM: 0.425531914893617\n",
      "Coef from both LR and SVM:  [0.03295863 0.04513138 0.03181499 0.0355501  0.02002024]\n",
      "0.025051334540969944\n",
      "[ 4  7  8 10]\n",
      "[[0 3]\n",
      " [3 4]]\n",
      "[[ 0 18]\n",
      " [18 24]]\n",
      "##################################################################\n",
      "Iteration = 3, L shape = (95156, 24)\n",
      "All agree, Number of outliers = 11\n",
      "All agree, Number of inliers = 94804\n",
      "num of inliers = 94804\n",
      "num of outliers = 28\n",
      "num of outliers = 28\n",
      "Training data shape:  (94832, 4)\n",
      "Training data F-1 0.689655172413793\n",
      "(94832, 3)\n",
      "(94832,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95078\n",
      "F-1 score from both LR and SVM: 0.425531914893617\n",
      "Coef from both LR and SVM:  [0.03047646 0.04602669 0.03378086 0.04535186]\n",
      "0.0320246137978725\n",
      "[ 7  8 10]\n",
      "[[0 2]\n",
      " [2 3]]\n",
      "[[ 0 12]\n",
      " [12 18]]\n",
      "##################################################################\n",
      "Iteration = 4, L shape = (95156, 18)\n",
      "All agree, Number of outliers = 15\n",
      "All agree, Number of inliers = 94841\n",
      "num of inliers = 94841\n",
      "num of outliers = 28\n",
      "num of outliers = 28\n",
      "Training data shape:  (94869, 3)\n",
      "Training data F-1 0.689655172413793\n",
      "(94869, 3)\n",
      "(94869,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95080\n",
      "F-1 score from both LR and SVM: 0.40816326530612246\n",
      "Coef from both LR and SVM:  [0.06737126 0.04307659 0.04008426]\n",
      "0.04008425599239542\n",
      "[7 8]\n",
      "[[0 2]\n",
      " [2 2]]\n",
      "[[ 0 12]\n",
      " [12 12]]\n",
      "##################################################################\n",
      "Iteration = 5, L shape = (95156, 12)\n",
      "All agree, Number of outliers = 21\n",
      "All agree, Number of inliers = 94962\n",
      "num of inliers = 94962\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (94990, 2)\n",
      "Training data F-1 0.689655172413793\n",
      "(94990, 3)\n",
      "(94990,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95072\n",
      "F-1 score from both LR and SVM: 0.4\n",
      "Coef from both LR and SVM:  [0.07523685 0.09878738]\n",
      "0.07523685146024006\n",
      "[8]\n",
      "[[0 1]\n",
      " [1 1]]\n",
      "[[0 6]\n",
      " [6 6]]\n",
      "##################################################################\n",
      "Iteration = 6, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94976\n",
      "num of inliers = 94976\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (95004, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "(95004, 3)\n",
      "(95004,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95075\n",
      "##################################################################\n",
      "Iteration = 7, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94976\n",
      "num of inliers = 94976\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (95004, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "(95004, 3)\n",
      "(95004,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95075\n",
      "##################################################################\n",
      "Iteration = 8, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94976\n",
      "num of inliers = 94976\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (95004, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "(95004, 3)\n",
      "(95004,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95075\n",
      "##################################################################\n",
      "Iteration = 9, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94976\n",
      "num of inliers = 94976\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (95004, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "(95004, 3)\n",
      "(95004,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95075\n",
      "##################################################################\n",
      "Iteration = 10, L shape = (95156, 6)\n",
      "All agree, Number of outliers = 30\n",
      "All agree, Number of inliers = 94976\n",
      "num of inliers = 94976\n",
      "num of outliers = 34\n",
      "num of outliers = 28\n",
      "Training data shape:  (95004, 1)\n",
      "Training data F-1 0.689655172413793\n",
      "(95004, 3)\n",
      "(95004,)\n",
      "F-1 score from SVM: 0.689655172413793\n",
      "precision score from SVM: 0.7142857142857143\n",
      "recall score from SVM: 0.6666666666666666\n",
      "length of prediction_high_conf_outliers: 28\n",
      "length of prediction high conf inliers:  95075\n"
     ]
    }
   ],
   "source": [
    "last_training_data_indexes = []\n",
    "counter = 0\n",
    "\n",
    "for i_range in range(0, 50):\n",
    "    print(\"##################################################################\")\n",
    "    print('Iteration = {}, L shape = {}'.format(i_range, np.shape(L)))\n",
    "    num_methods = np.shape(L)[1]\n",
    "\n",
    "#     agree_outlier_indexes = (np.sum(L,axis=1)==np.shape(L)[1])\n",
    "#     print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "#     agree_inlier_indexes = (np.sum(L,axis=1)==0)\n",
    "#     print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "#     all_inlier_indexes = np.union1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "#     print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "\n",
    "#     disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "\n",
    "    ########################################################################\n",
    "\n",
    "    agree_outlier_indexes = np.sum(L,axis=1)==np.shape(L)[1]\n",
    "    print('All agree, Number of outliers = {}'.format(sum(agree_outlier_indexes)))\n",
    "    agree_inlier_indexes = np.sum(L,axis=1)==0\n",
    "    print('All agree, Number of inliers = {}'.format(sum(agree_inlier_indexes)))\n",
    "\n",
    "    disagree_indexes = np.where(np.logical_or(np.sum(L,axis = 1)==0, np.sum(L,axis = 1)==num_methods)==0)[0]\n",
    "    # print('Number of disagreed points = {}'.format(len(disagree_indexes)))\n",
    "    # print('Number of disagreed points (true outliers) = {}'.format(sum(y[disagree_indexes] == 1)))\n",
    "    # print('Number of disagreed points (true inliers) = {}'.format(sum(y[disagree_indexes] == 0)))\n",
    "\n",
    "#     all_inlier_indexes = np.where(agree_inlier_indexes)[0]\n",
    "    all_inlier_indexes = np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    if len(prediction_high_conf_inliers) >0:\n",
    "        all_inlier_indexes = np.intersect1d(np.setdiff1d(np.where(agree_inlier_indexes)[0], prediction_high_conf_outliers), prediction_high_conf_inliers)\n",
    "    print('num of inliers = {}'.format(np.shape(all_inlier_indexes)[0]))\n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], self_agree_index_list)\n",
    "\n",
    "#     if(len(np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 0 and\n",
    "#       (len(np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)) > 2000)):\n",
    "#         all_outlier_indexes = np.intersect1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     else:\n",
    "    all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "#     if(len(all_outlier_indexes) > 1000):\n",
    "#         all_outlier_indexes = np.random.RandomState(1).permutation(all_outlier_indexes)[:1000]\n",
    "        \n",
    "#     all_outlier_indexes = np.union1d(np.where(agree_outlier_indexes)[0], prediction_high_conf_outliers)\n",
    "    print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    all_inlier_indexes = np.setdiff1d(all_inlier_indexes, prediction_classifier_disagree)\n",
    "    \n",
    "    self_agree_index_list = []\n",
    "    if((len(all_outlier_indexes) == 0) or (len(all_inlier_indexes)/ len(all_outlier_indexes) > 1000)):\n",
    "        for i in range(0, len(index_range)):\n",
    "            if(index_range[i,1]-index_range[i,0] <= 6):\n",
    "                continue\n",
    "            temp_index = disagree_indexes[np.where(np.sum(L[disagree_indexes][:,index_range[i,0]: index_range[i,1]], axis = 1)==(index_range[i,1]-index_range[i,0]))[0]]\n",
    "            self_agree_index_list = np.union1d(self_agree_index_list, temp_index)\n",
    "        self_agree_index_list = [int(i) for i in self_agree_index_list]\n",
    "#     self_agree_index_list = np.random.RandomState(1).permutation(self_agree_index_list)[:500]\n",
    "    all_outlier_indexes = np.union1d(all_outlier_indexes, self_agree_index_list)\n",
    "    all_outlier_indexes = np.setdiff1d(all_outlier_indexes, prediction_classifier_disagree)\n",
    "    print('num of outliers = {}'.format(np.shape(all_outlier_indexes)[0]))\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    data_indexes = np.concatenate((all_inlier_indexes, all_outlier_indexes), axis = 0)\n",
    "    data_indexes = np.array([int(i) for i in data_indexes])\n",
    "    labels = np.concatenate((np.zeros(len(all_inlier_indexes)), np.ones(len(all_outlier_indexes))), axis = 0)\n",
    "    transformer = RobustScaler().fit(scores_for_training)\n",
    "    scores_transformed = transformer.transform(scores_for_training)\n",
    "    training_data = scores_transformed[data_indexes]\n",
    "    print('Training data shape: ', np.shape(training_data))\n",
    "    training_data_F1.append(metrics.f1_score(y[data_indexes], labels))\n",
    "    print('Training data F-1', metrics.f1_score(y[data_indexes], labels))\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "#     clf = SVC(gamma='auto', probability=True, random_state=0)\n",
    "#     clf.fit(training_data, labels)\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(training_data, labels) \n",
    "    clf_predictions = clf.predict(scores_transformed)\n",
    "    clf_predict_proba = clf.predict_proba(scores_transformed)[:,1]\n",
    "#     print(\"F-1 score from LR:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba > 0.5])))\n",
    "    \n",
    "    \n",
    "    transformer = RobustScaler().fit(X)\n",
    "    X_transformed = transformer.transform(X)\n",
    "    X_training_data = X_transformed[data_indexes]\n",
    "    print(np.shape(X_training_data))\n",
    "    print(np.shape(labels))\n",
    "\n",
    "    clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "    clf_X.fit(X_training_data, labels)\n",
    "    clf_predictions_X = clf_X.predict(X_transformed)\n",
    "    clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "    print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    print(\"precision score from SVM:\",metrics.precision_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    print(\"recall score from SVM:\",metrics.recall_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "    cur_f1_scores.append(metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))\n",
    "        \n",
    "    agreed_outlier_indexes = np.where(np.sum(L,axis=1)==np.shape(L)[1])[0]\n",
    "    agreed_inlier_indexes = np.where(np.sum(L,axis=1)==0)[0]\n",
    "        \n",
    "    prediction_result_list.append(clf_predict_proba)\n",
    "    classifier_result_list.append(clf_predict_proba_X)\n",
    "    \n",
    "    prediction_list.append(np.array([int(i) for i in clf_predictions]))\n",
    "    \n",
    "    prediction_high_conf_outliers = np.intersect1d(np.where(prediction_result_list[-1] > high_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] > high_confidence_threshold)[0])\n",
    "    print('length of prediction_high_conf_outliers:' , len(prediction_high_conf_outliers))\n",
    "    prediction_high_conf_inliers = np.intersect1d(np.where(prediction_result_list[-1] < low_confidence_threshold)[0],\n",
    "                                                   np.where(classifier_result_list[-1] < low_confidence_threshold)[0])\n",
    "    print('length of prediction high conf inliers: ', len(prediction_high_conf_inliers))\n",
    "    \n",
    "    temp_prediction = np.array([int(i) for i in prediction_result_list[-1] > 0.5])\n",
    "    temp_classifier = np.array([int(i) for i in classifier_result_list[-1] > 0.5])\n",
    "    prediction_classifier_disagree = np.where(temp_prediction != temp_classifier)[0]\n",
    "    \n",
    "    if np.max(coef_index_range) >= 2:\n",
    "        if(len(prediction_high_conf_outliers) > 0 and len(prediction_high_conf_inliers) > 0):\n",
    "            new_data_indexes = np.concatenate((prediction_high_conf_outliers, prediction_high_conf_inliers), axis = 0)\n",
    "            new_data_indexes = np.array([int(i) for i in new_data_indexes])\n",
    "            new_labels = np.concatenate((np.ones(len(prediction_high_conf_outliers)), np.zeros(len(prediction_high_conf_inliers))), axis = 0)\n",
    "            clf_prune_2 = LogisticRegression(random_state=0, penalty='l2', max_iter=max_iter).fit(scores_transformed[new_data_indexes], new_labels) \n",
    "            print(\"F-1 score from both LR and SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_prune_2.predict_proba(scores_transformed)[:,1] > 0.5])))\n",
    "            print('Coef from both LR and SVM: ', clf_prune_2.coef_[0])\n",
    "            combined_coef = clf_prune_2.coef_[0]  \n",
    "        else:\n",
    "            print('Coef from normal training: ', clf.coef_[0])\n",
    "            combined_coef = clf.coef_[0]\n",
    "            print('Combined Coef: ',  combined_coef)\n",
    "\n",
    "        if(np.max(coef_index_range) > 2 or \n",
    "           ((np.max(combined_coef)/np.min(combined_coef) >= 1.1) and np.max(coef_index_range) >= 2)):\n",
    "            if(len(set(combined_coef)) > 1):\n",
    "                cur_clf_coef = combined_coef \n",
    "                cutoff = max(max(0, np.mean(combined_coef)-np.std(combined_coef)),min(combined_coef))\n",
    "                print(cutoff)\n",
    "\n",
    "                remain_indexes_after_cond = (cur_clf_coef > cutoff) #np.logical_and(cur_clf_coef > cutoff, abs(cur_clf_coef) > 0.01) # # \n",
    "                remain_params_tracking = remain_params_tracking[remain_indexes_after_cond]\n",
    "                print(remain_params_tracking)\n",
    "                remain_indexes_after_cond_expanded = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s_e_range = coef_index_range[i,1]-coef_index_range[i,0]\n",
    "                    s1, e1 = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    s2, e2 = index_range[i,0], index_range[i,1]\n",
    "                    saved_indexes = np.where(cur_clf_coef[s1:e1] > cutoff)[0]\n",
    "                    for j in range(N_size):\n",
    "                        remain_indexes_after_cond_expanded.extend(np.array(saved_indexes) + j * s_e_range + s2)\n",
    "\n",
    "                new_coef_index_range_seq = []\n",
    "                for i in range(0, len(coef_index_range)): #\n",
    "                    s, e = coef_index_range[i,0], coef_index_range[i,1]\n",
    "                    new_coef_index_range_seq.append(sum((remain_indexes_after_cond)[s:e]))\n",
    "\n",
    "                coef_index_range = []\n",
    "                index_range = []\n",
    "                cur_sum = 0\n",
    "                for i in range(0, len(new_coef_index_range_seq)):\n",
    "                    coef_index_range.append([cur_sum, cur_sum + new_coef_index_range_seq[i]])\n",
    "                    index_range.append([cur_sum * 6, 6 * (cur_sum + new_coef_index_range_seq[i])])\n",
    "                    cur_sum += new_coef_index_range_seq[i]\n",
    "\n",
    "                coef_index_range = np.array(coef_index_range)\n",
    "                index_range = np.array(index_range)\n",
    "                print(coef_index_range)\n",
    "                print(index_range)\n",
    "\n",
    "                L=L[:,remain_indexes_after_cond_expanded]\n",
    "                scores_for_training = scores_for_training[:, remain_indexes_after_cond]\n",
    "    if((len(last_training_data_indexes) == len(data_indexes)) and \n",
    "       (sum(last_training_data_indexes == data_indexes) == len(data_indexes)) and \n",
    "       (np.max(coef_index_range) < 2)):\n",
    "        counter =  counter + 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    if(counter > 3):\n",
    "        break\n",
    "    last_training_data_indexes = data_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GT label to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score from SVM: 0.8\n"
     ]
    }
   ],
   "source": [
    "# random select the same number of labels\n",
    "# data_indexes = np.random.permutation(len(y))[:len(data_indexes)]\n",
    "# train a SVM classifier\n",
    "clf_X = SVC(gamma='auto', probability=True, random_state=0)\n",
    "transformer = RobustScaler().fit(X)\n",
    "X_transformed = transformer.transform(X)\n",
    "X_training_data = X_transformed[data_indexes]\n",
    "clf_X.fit(X_training_data, y[data_indexes])\n",
    "clf_predictions_X = clf_X.predict(X_transformed)\n",
    "clf_predict_proba_X = clf_X.predict_proba(X_transformed)[:,1]\n",
    "print(\"F-1 score from SVM:\",metrics.f1_score(y, np.array([int(i) for i in clf_predict_proba_X > 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
